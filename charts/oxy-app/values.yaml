# Default values for oxy-app
# This is a YAML-formatted file.

# Application configuration
name: oxy-app

app:
  image: ghcr.io/oxy-hq/oxy
  imageTag: ""
  port: 3000
  replicaCount: 1
  imagePullPolicy: IfNotPresent
  # Optional override for the container command. When empty, the chart will
  # use the default shell wrapper that runs `oxy serve` (readonly if gitSync disabled).
  # Example: ["/app/bin/oxy", "serve"]
  command: []

# Semantic Engine configuration
semanticEngine:
  enabled: false
  image: ghcr.io/oxy-hq/oxy-semantic-engine
  # imageTag defaults to app.imageTag if not specified
  imageTag: ""
  imagePullPolicy: IfNotPresent

# Ingress configuration
# Enable and configure Kubernetes Ingress for the application.
ingress:
  enabled: false
  # ingressClassName allows selecting a specific IngressClass (empty = use default)
  ingressClassName: ""
  annotations: {}
  # Default path and pathType for the first host entry
  path: /
  pathType: Prefix
  # Primary hosts list. Each entry can contain a host and optional paths.
  hosts:
    - host: chart-example.local
      paths: []
  # TLS configuration. Example:
  # tls:
  #   - hosts:
  #       - chart-example.local
  #     secretName: chart-example-tls
  tls: []

# Resource configuration
resources:
  requests:
    cpu: 250m
    memory: 512Mi
  limits:
    cpu: 1000m
    memory: 2Gi

# Environment variables
env:
  OXY_STATE_DIR: /workspace/oxy_data
  # Optional explicit database URL. If set, this takes precedence over other DB settings.
  OXY_DATABASE_URL: ""

configMap:
  enabled: false
  # free-form map of key -> value to be included in the ConfigMap
  data: {}

# Service Account for IRSA
serviceAccount:
  create: true
  name: ""  # If empty, will auto-generate using chart name
  annotations: {}
  # Example: eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/oxy-app-role

# Persistent storage
persistence:
  enabled: true
  storageClassName: ""
  size: 20Gi
  accessMode: ReadWriteOnce
  # Mount path inside the container where the PVC will be mounted
  mountPath: /workspace
  # Folder under the mountPath to use as the OXY_STATE_DIR
  folder: oxy_data
  # Optional metadata for the PVC
  annotations: {}
  labels: {}
  # volumeMode can be "Filesystem" or "Block"
  volumeMode: Filesystem
  # Optional selector for matching existing PVs
  selector: {}

# Node selection and tolerations
nodeSelector:

tolerations:

# Node affinity configuration (optional). Provide a map compatible with
# Kubernetes PodAffinity/PodAntiAffinity/NodeAffinity specs. An empty map
# here prevents template engines from erroring when `.Values.affinity` is
# referenced but not set by the user.
affinity: {}

# Service configuration
service:
  type: ClusterIP
  port: 80
  targetPort: 3000
  # Optionally override the service resource name. If empty, uses the chart fullname
  name: ""

# Headless service for StatefulSet
headlessService:
  enabled: true

# Probes configuration
livenessProbe:
  httpGet:
    path: /
    port: 3000
  initialDelaySeconds: 10
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /
    port: 3000
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Security context
securityContext:
  fsGroup: 1000

# External secrets configuration
externalSecrets:
  # When true, the chart will create ExternalSecret CRs as configured below.
  # Default is false: the chart will NOT create ESO CRs and expects secrets to be
  # created externally (recommended for production).
  create: false

  # Generic lists for mounting secrets into the pod. Leave empty by default.
  # 1) Env secrets: list of existing Kubernetes Secret names whose keys will be
  #    concatenated into the application .env file. Each Secret will be mounted
  #    under /secrets/env/<secret-name> and all files will be concatenated.
  envSecretNames: []

  # Optional per-secret mapping allowing the user to provide a map of
  # key -> remoteKey for a given secret name. Used only when creating ExternalSecrets.
  # envSecretMappings:
  #   my-env-secret:
  #     DATABASE_URL: /path/to/database/url
  envSecretMappings: {}

  # 2) File secrets: list of objects that represent a secret and a specific key
  #    inside that secret which should be copied into the pod as a file.
  #    Example:
  #    fileSecrets:
  #      - name: my-datawarehouse-secret
  #        key: bigquery-key.json
  #        dest: bigquery-key.json  # optional, defaults to key
  fileSecrets: []

  # External Secrets Operator configuration (used only if create: true)
  storeRef:
    name: ""
    kind: ""

# Single SSH key configuration (preferred for simple setups)
# Use `sshKey.secretName` to point to an existing Secret in production,
# or provide `sshKey.privateKey` (inline) for development/testing only.
sshKey:
  secretName: ""  # If empty, defaults to gitSync.sshSecretName
  privateKey: ""  # Inline private SSH key (DO NOT commit to VCS)
  knownHosts: ""  # Optional known_hosts content (multiline)

# Git sync sidecar configuration
gitSync:
  period: 15s
  repository: ""
  branch: main
  sshSecretName: oxy-git-ssh
  enabled: false
  # IMPORTANT: Per git-sync documentation, when using persistent volumes at filesystem root,
  # the --root must be a SUB-DIRECTORY of the mount point to avoid conflicts with filesystem
  # metadata like 'lost+found'. This value should be a DIRECTORY NAME (not an absolute path)
  # that will be appended to persistence.mountPath. Defaults to "git" -> /workspace/git
  root: ""
  # Link directory name (not absolute path) for the symlink pointing to the latest synced
  # revision. Will be appended to persistence.mountPath. Defaults to "current" -> /workspace/current
  link: ""
  # Working directory subdirectory (optional). When set, this subdirectory path will be
  # appended to the git link directory to set as the container's workingDir.
  # For example, if workingDir: "backend", the final working directory will be:
  # /workspace/current/backend (assuming default link and mountPath values)
  # Leave empty to use the root of the cloned repository.
  workingDir: ""
  # Image pull policy for the git-sync init container. Valid values: Always, IfNotPresent, Never
  imagePullPolicy: IfNotPresent

  # GitHub App authentication (optional)
  # REQUIRED fields when using GitHub App authentication:
  #   - privateKey: GitHub App PEM private key
  #   - applicationId: GitHub App Application ID
  #   - installationId: GitHub App Installation ID
  #
  # The private key file is passed via --github-app-private-key-file argument.
  # Environment variables set: GITSYNC_GITHUB_APP_APPLICATION_ID, GITSYNC_GITHUB_APP_INSTALLATION_ID
  githubApp:
    secretName: ""  # Optional: existing secret name containing GitHub App data (if set, inline values are ignored)
    # Required fields (when not using secretName):
    privateKey: ""  # REQUIRED: PEM private key contents for GitHub App (DO NOT commit in production)
    applicationId: ""  # REQUIRED: GitHub App Application ID
    installationId: ""  # REQUIRED: Installation ID for GitHub App auth
    # Secret key names (used when creating secrets or reading from existing secrets):
    privateKeyKey: "github_app_private_key"  # key name in secret for private key
    applicationIdKey: "github_app_application_id"  # key name in secret for app id
    installationIdKey: "github_app_installation_id"  # key name in secret for installation id

# HTTP authentication for git-sync (for HTTPS git repositories)
# Use this when cloning from HTTPS URLs that require username/password authentication
httpAuth:
  # Username for HTTP authentication
  username: ""
  # Inline password (for development/testing only - NOT RECOMMENDED for production)
  # For production, use secretName to reference an existing secret
  password: ""
  # Reference to an existing Kubernetes secret containing the password
  # The secret should have a key named 'password' (or specify passwordKey)
  secretName: ""
  # Key name in the secret that contains the password (defaults to 'password')
  passwordKey: "password"

database:
  # Enable or disable the postgres subchart
  postgres:
    enabled: false
    # Host for the postgres service created by the subchart
    # Format: servicename.namespace.svc.cluster.local
    # Common patterns:
    # - {release-name}-postgres (most common for groundhog2k chart)
    # - {subchart-name} (if using alias)
    # Leave empty to auto-generate as: {release-name}-postgres.{namespace}.svc.cluster.local
    host: ""
    port: 5432
    # Note: Connection details are inferred from the postgres.* configuration below
    # No need to duplicate userDatabase configuration here

  # Enable or disable the clickhouse subchart
  clickhouse:
    enabled: false
    # Host for the ClickHouse service created by the subchart
    # Leave empty to auto-generate as: {release-name}-clickhouse.{namespace}.svc.cluster.local
    host: ""
    # HTTP port (used by oxy-app for queries)
    httpPort: 8123
    # TCP/Native port (used by otel-collector)
    tcpPort: 9000

  # External DB settings (optional)
  external:
    enabled: false
    # If enabled, the external DB may rely on secrets managed by the user.
    # Use `externalSecrets.envSecretNames` and `externalSecrets.fileSecrets` to
    # declare and mount any required secrets into the pod.
    storeRef:
      name: ""
      kind: SecretStore

    envSecret:
      backend: ""
      path: ""
      key: ""

    dataWarehouseSecret:
      backend: ""
      path: ""
      key: ""

    # Optional connection details for an external database. Leave empty to
    # let callers supply a full connection string via `connectionString` or
    # rely on mounted secrets.
    connectionString: ""
    user: ""
    password: ""
    host: ""
    port: 5432
    database: ""

# Configuration for the postgres subchart (groundhog2k/postgres)
# When database.postgres.enabled is true, these values configure the postgres subchart
# The fullnameOverride controls the service name created by the subchart
# Example: if fullnameOverride is "my-postgres", the service will be "my-postgres"
# If not set, the service name follows Helm's pattern: {release-name}-postgres
postgres:
  # Override the full name of the postgres subchart resources
  # This determines the service name that will be created
  # Leave empty to use default: {release-name}-postgres
  fullnameOverride: ""
  settings:
    superuserPassword:
      value: postgres
  userDatabase:
    name:
      value: postgres
    user:
      value: postgres
    password:
      value: postgres
  storage:
    requestedSize: 8Gi
    className: ""

# Configuration for the clickhouse subchart (Bitnami)
# When database.clickhouse.enabled is true, these values configure the subchart
# See: https://artifacthub.io/packages/helm/bitnami/clickhouse
clickhouseSubchart:
  # Override the full name of the clickhouse subchart resources
  # This determines the service name that will be created
  # Leave empty to use default: {release-name}-clickhouse
  fullnameOverride: ""
  # Image configuration - use legacy Bitnami images (non-paid)
  image:
    repository: bitnamilegacy/clickhouse
  # Authentication configuration
  auth:
    username: "default"
    password: "clickhouse"
    # Use existing secret for credentials (recommended for production)
    existingSecret: ""
    existingSecretPasswordKey: "password"
  # ClickHouse Keeper (required for single-node setup, alternative to ZooKeeper)
  keeper:
    enabled: true
    image:
      repository: bitnamilegacy/clickhouse-keeper
  # ZooKeeper (alternative to Keeper, disabled by default)
  zookeeper:
    enabled: false
    image:
      repository: bitnamilegacy/zookeeper
  # Shard and replica configuration
  shards: 1
  replicaCount: 1
  # Resource configuration
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi
  # Persistence configuration
  persistence:
    enabled: true
    size: 10Gi
    storageClass: ""

# ClickHouse configuration (shared between oxy-app and otel-collector)
# This configures the ClickHouse connection used by the main application
# and optionally by the OpenTelemetry Collector for trace/metrics export
clickhouse:
  enabled: false
  # HTTP endpoint for oxy-app (e.g., http://clickhouse:8123)
  url: ""
  # TCP endpoint for otel-collector (e.g., tcp://clickhouse:9000)
  # If empty, derived from url by replacing http->tcp and port 8123->9000
  tcpEndpoint: ""
  database: "otel"
  username: "default"
  # Password can be provided inline (dev only) or via existingSecret
  password: ""
  # Use existing secret for credentials (recommended for production)
  # The secret should contain keys for username and password
  existingSecret:
    name: ""
    usernameKey: "username"
    passwordKey: "password"

# Allow users to supply arbitrary initContainers and sidecar containers.
# Each entry should be a Kubernetes container spec. Examples below show
# how to mount a secret and run a simple command. These are merged into
# the Pod spec as-is; the user is responsible for valid container specs.
extraInitContainers: []

# Extra sidecar containers to run alongside the main application container.
# Example usage:
# extraSidecars:
#   - name: my-sidecar
#     image: busybox:1.36
#     imagePullPolicy: IfNotPresent
#     command: ["sh", "-c", "while true; do echo sidecar; sleep 60; done"]
#     volumeMounts:
#       - name: workspace
#         mountPath: /workspace
extraSidecars: []

# OpenTelemetry Collector sidecar configuration
# Collects traces/metrics and exports to ClickHouse or other backends
otelCollector:
  enabled: false
  image: otel/opentelemetry-collector-contrib
  imageTag: "latest"
  imagePullPolicy: IfNotPresent

  # Resource limits for the collector
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # Receiver ports
  ports:
    otlpGrpc: 4317
    otlpHttp: 4318
    metrics: 8888

  # Processor configuration
  processors:
    batch:
      timeout: 10s
      sendBatchSize: 100
      sendBatchMaxSize: 1000
    memoryLimiter:
      checkInterval: 1s
      limitMib: 512

  # ClickHouse exporter configuration
  # By default, uses the shared clickhouse.* config above
  # Set overrides here for otel-collector specific settings
  clickhouse:
    enabled: true
    # Override endpoint (if empty, uses shared clickhouse.tcpEndpoint or derived from clickhouse.url)
    endpoint: ""
    # Override database (if empty, uses shared clickhouse.database)
    database: ""
    # Override credentials (if empty, uses shared clickhouse.username/password)
    username: ""
    password: ""
    # Table configuration
    logsTableName: "otel_logs"
    tracesTableName: "otel_traces"
    metricsTableName: "otel_metrics"
    # Performance settings
    asyncInsert: true
    compress: "lz4"
    createSchema: true
    # Data retention (TTL)
    ttl: "72h"
    # Timeout and retry settings
    timeout: "5s"
    retry:
      enabled: true
      initialInterval: "5s"
      maxInterval: "30s"
      maxElapsedTime: "300s"

  # Debug exporter (useful for troubleshooting)
  debug:
    enabled: false
    verbosity: "detailed"

  # Service telemetry (collector's own logs)
  telemetry:
    logs:
      level: "info"

# PodDisruptionBudget configuration
pdb:
  enabled: false
  # Either set minAvailable or maxUnavailable. When both are set, minAvailable takes precedence.
  # Examples: 1, "50%"
  minAvailable: ""
  # Examples: 1, "25%". Leave empty to not set.
  maxUnavailable: ""
  # Optional selector labels to narrow the PDB selector. Merges with chart selectorLabels when provided.
  selector: {}
